{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25959d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "etl = '<center><img src=\"https://www.dataprix.com/files/uploads/32image/Respinosamilla_bi/etl_chart.jpg\" width=\"400\" ></center>'\n",
    "etl2 = '<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/f/fa/Conventional_ETL_Diagram.jpg\" width=\"1000\" ></center>'\n",
    "\n",
    "import sqlalchemy #orm\n",
    "import pandas as pd #manejo de tablas\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import requests # solicitudes http\n",
    "import json \n",
    "from datetime import datetime\n",
    "import datetime\n",
    "import sqlite3 #bd\n",
    "\n",
    "from dotenv import load_dotenv, dotenv_values #pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016c515f",
   "metadata": {},
   "source": [
    "- Nombre: Nicolás Otárola Teillier\n",
    "- Profesor: Juan Pablo Salazar\n",
    "- Ramo: Arquitectura de Sistemas\n",
    "- Fecha: 04/10/2021\n",
    "- Git: https://github.com/NicolasOtarolaTeillier/arquitectura-sistemas-2021-2\n",
    "- Api Spotify: https://developer.spotify.com/console/get-recently-played/\n",
    "- Cliente sql: https://dbeaver.io/\n",
    "- Referencias:\n",
    " - https://www.youtube.com/watch?v=eg8t2-E69ew\n",
    " - https://aprenderbigdata.com/herramientas-etl/\n",
    " - https://www.obsbusiness.school/blog/herramientas-etl-que-son-y-cuales-recomendamos\n",
    " - https://www.dataprix.com/es/blog-it/respinosamilla/herramientas-etl-son-valen-productos-mas-conocidos-etls-open-source\n",
    " - https://github.com/karolina-sowinska/free-data-engineering-course-for-beginners/blob/master/main.py\n",
    " - https://www.youtube.com/channel/UCAxnMry1lETl47xQWABvH7g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85996b79",
   "metadata": {},
   "source": [
    "### Indice:\n",
    "\n",
    "1. ¿Para que sirven?\n",
    "2. ¿Cómo funcionan?\n",
    "3. ¿Cuáles son las más usadas?\n",
    "4. Ejemplo práctico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db66b683",
   "metadata": {},
   "source": [
    " # Herramientas ETL y el patrón de tuberías"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53216780",
   "metadata": {},
   "source": [
    "### Conceptos clave:\n",
    "\n",
    "- **Pipeline (Tubería)**: \n",
    " - para los igenieros de datos, **es una ruta de un extremo a otro**, donde cada ruta tiene una o varias fuentes y sistemas de destino para acceder y manipular los datos disponibles. Dentro de cada tubería, los datos pasan por numerosas etapas de transformacion, validacion, normalizacion.\n",
    " \n",
    "- **Extraer (Extract)**. Consiste en la extracción de datos de fuentes heterogéneas.\n",
    "\n",
    "- **Transformar (Transform**). De los datos en bruto extraídos, pasamos a transformarlos en información y conocimiento útiles para la empresa y para sus objetivos. (limpiar, normalizar, validacion, etc)\n",
    "\n",
    "- **Cargar (Load)**. Con los datos “purificados”, es decir, convertidos en información útil, pasamos a almacenar esta en un mismo lugar. Es lo que se conoce como almacén de datos o data mart. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2356265c",
   "metadata": {},
   "source": [
    "## 1 ¿Para que sirven?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3847a1b",
   "metadata": {},
   "source": [
    "- permite a las organizaciones mover datos desde múltiples fuentes, reformatearlos y limpiarlos, y cargarlos en otra base de datos, data mart, o data warehouse para analizar, o en otro sistema operacional para apoyar un proceso de negocio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2725f298",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<center><img src=\"https://www.dataprix.com/files/uploads/32image/Respinosamilla_bi/etl_chart.jpg\" width=\"400\" ></center>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(etl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49c88e6",
   "metadata": {},
   "source": [
    "## 2 ¿Cómo funcionan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cd27870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/f/fa/Conventional_ETL_Diagram.jpg\" width=\"1000\" ></center>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(etl2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c7a53e",
   "metadata": {},
   "source": [
    "##### Algunas Funcionalidades generales de los ETL\n",
    "- Control de la extracción de los datos y su automatización, disminuyendo el tiempo empleado en el descubrimiento de procesos no documentados, minimizando el margen de error y permitiendo mayor flexibilidad.\n",
    "- Acceso a diferentes tecnologías, haciendo un uso efectivo del hardware, software, datos y recursos humanos existentes.\n",
    "- Proporcionar la gestión integrada del Data Warehouse y los Data Marts existentes, integrando la extracción, transformación y carga para la construcción del Data Warehouse corporativo y de los Data Marts.\n",
    "- Uso de la arquitectura de metadatos, facilitando la definición de los objetos de negocio y las reglas de consolidación.\n",
    "- Acceso a una gran variedad de fuentes de datos diferentes.\n",
    "- Manejo de excepciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf014b5",
   "metadata": {},
   "source": [
    "## 3 ¿Cuáles son las más usadas?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3853d68b",
   "metadata": {},
   "source": [
    "https://aprenderbigdata.com/herramientas-etl/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fab460",
   "metadata": {},
   "source": [
    "## 4 Ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f90522",
   "metadata": {},
   "source": [
    "##### VERIFICACIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a7ebdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_valid_data(df: pd.DataFrame)-> bool:\n",
    "    # Check if datafreame is empty \n",
    "    if df.empty:\n",
    "        print(\"no song downloaded, finishing execution\")\n",
    "        return False\n",
    "        \n",
    "    # Primary Key Check\n",
    "    if pd.Series(df['played_at']).is_unique:\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception(\"Primary Key Check is violated\")\n",
    "    \n",
    "    # Check for nulls\n",
    "    if df.isnull().values.any():\n",
    "        raise Exception(\"Null valued found\")\n",
    "\n",
    "    # Check that all timestamps are of yesterday's date\n",
    "    #yesterday = datetime.datetime.now() - datetime.timedelta(days=1)\n",
    "    #yesterday = yesterday.replace(hour=0, minute=0, second=0,microsecond=0)\n",
    "    \n",
    "    #timestamps = df[\"timestamp\"].tolist()\n",
    "    #for timestamp in tçimestamps:\n",
    "    #    if datetime.datetime.strptime(timestamp,\"%Y-%m-%d\") != yesterday:\n",
    "    #        raise Exception(\"At least one of the returned songs does not come from within the last 24 hours\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e89a6a2",
   "metadata": {},
   "source": [
    "##### ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a9f59b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def ETL(TOKEN,DATABASE_LOCATION, LIMITE, LISTA_REPRODUCCION):\n",
    "       \n",
    "                                             # headers for request                             \n",
    "    headers ={\n",
    "        \"Accept\" : \"application/json\",\n",
    "        \"Content-Type\" : \"application/json\",\n",
    "        \"Authorization\" : \"Bearer {token}\".format(token=TOKEN)\n",
    "    }\n",
    "                                            # ETL process : Extract\n",
    "        \n",
    "    r = requests.get(\"{endpoint}?limit={limit}\".format(endpoint = LISTA_REPRODUCCION,limit=LIMITE),headers=headers)\n",
    "    data = r.json()\n",
    "    print(data)\n",
    "    \n",
    "    try :\n",
    "        data[\"error\"] \n",
    "        print(\"Error : \",data[\"error\"])\n",
    "        return\n",
    "    except:\n",
    "        print(\"Response recived!\")\n",
    "    \n",
    "                                            # ETL process : Transform\n",
    "        \n",
    "    song_names, artist_names, played_at_list= [],[],[]\n",
    "    for song in data[\"items\"]:\n",
    "\n",
    "        song_names.append(song[\"track\"][\"name\"])\n",
    "        artist_names.append(song[\"track\"][\"album\"][\"artists\"][0][\"name\"])\n",
    "        played_at_list.append(song[\"played_at\"])\n",
    "        \n",
    "    song_dict = {\"song_name\": song_names,\"artist_name\": artist_names,\"played_at\" : played_at_list}\n",
    "    \n",
    "                                        \n",
    "        \n",
    "    clean_song_df = pd.DataFrame(song_dict, columns = [\"song_name\",\"artist_name\",\"played_at\"])\n",
    "    \n",
    "                                                 # Validate\n",
    "    if check_if_valid_data(clean_song_df):\n",
    "        print(\"Data valid, proceed to Load stage\")\n",
    "        \n",
    "                                            # ETL process : Load\n",
    "    \n",
    "    engine = sqlalchemy.create_engine(DATABASE_LOCATION)\n",
    "    conn = sqlite3.connect('my_played_tracks.sqlite')\n",
    "    cursosr = conn.cursor()\n",
    "    \n",
    "    sql_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS my_played_tracks(\n",
    "        song_name VARCHAR(200),\n",
    "        artist_name VARCHAR(200),\n",
    "        played_at VARCHAR(200),\n",
    "        CONSTRAINT primary_key_constraint PRIMARY KEY (played_at)\n",
    "    )\n",
    "    \"\"\"\n",
    "    cursosr.execute(sql_query)\n",
    "    print(\"Opened database succesfully\")\n",
    "    try :\n",
    "        clean_song_df.to_sql(\"my_played_tracks\",engine, index=False, if_exists='append')\n",
    "    except:\n",
    "        print(\"Data already exist in the database\")\n",
    "    \n",
    "    \n",
    "    display(clean_song_df)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50f0d70",
   "metadata": {},
   "source": [
    " * Ejemplo de configuración de variables de entorno : \n",
    "\n",
    "~~~\n",
    "TOKEN=BQDZjCRsJWbhf5C8npbQtYnOe\n",
    "DB=sqlite:///my_played_tracks.sqlite\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ce7cb5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "env = dotenv_values(\".env\") # importar variables de entorno\n",
    "DATABASE_LOCATION = env[\"DB\"]\n",
    "TOKEN = env[\"TOKEN\"]\n",
    "LIMITE = 20\n",
    "ENDPOINT = \"https://api.spotify.com/v1/me/player/recently-played\"\n",
    "\n",
    "ETL(TOKEN, DATABASE_LOCATION, LIMITE, ENDPOINT) # ejecutamos el ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95503a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb520fce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
